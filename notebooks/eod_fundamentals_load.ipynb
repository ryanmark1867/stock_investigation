{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOD: load from fundamentals API\n",
    "\n",
    "- use the fundamentals API to get details about tickers and ETFS\n",
    "- get ticker values from exchange lists and then load fundamentals from that ticker list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import yaml\n",
    "from datetime import date\n",
    "import requests\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "# For reading stock data from yahoo\n",
    "#import pandas_datareader as pdr\n",
    "from pandas_datareader.data import DataReader\n",
    "# import yahoo_fin.stock_info as si\n",
    "\n",
    "# For time stamps\n",
    "from datetime import datetime\n",
    "\n",
    "# for LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input\n",
    "from keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "# access datasets from quandl.com - need to pip install Quandl to use\n",
    "import quandl\n",
    "config_file = 'eod_test_config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is: C:\\personal\\karma_stocks_2021\\stock_investigation\\notebooks\n",
      "path_to_yaml C:\\personal\\karma_stocks_2021\\stock_investigation\\notebooks\\eod_test_config.yml\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "current_path = os.getcwd()\n",
    "print(\"current directory is: \"+current_path)\n",
    "\n",
    "path_to_yaml = os.path.join(current_path, config_file)\n",
    "print(\"path_to_yaml \"+path_to_yaml)\n",
    "try:\n",
    "    with open (path_to_yaml, 'r') as c_file:\n",
    "        config = yaml.safe_load(c_file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config parms\n",
    "parms = {}\n",
    "eod_token = config['general']['eod_token']\n",
    "eod_historical_token = config['general']['eod_historical_token']\n",
    "fundamentals_directory = config['files']['fundamentals_directory']\n",
    "exchange_list = config['exchange_json_list']\n",
    "etf_list = config['etf_list']\n",
    "\n",
    "from_date = config['general']['master_start']\n",
    "to_date = config['general']['master_end']\n",
    "parms['master_date_mode'] = config['general']['master_date_mode']\n",
    "parms['master_start'] = config['general']['master_start']\n",
    "parms['master_end'] = config['general']['master_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataReader: https://riptutorial.com/pandas/topic/1912/pandas-datareader\n",
    "# https://pandas-datareader.readthedocs.io/en/latest/remote_data.html\n",
    "# \n",
    "# Set up End and Start times for data grab\n",
    "# check to see if start and end dates are hard-coded with master dates\n",
    "def set_start_end():\n",
    "    if parms['master_date_mode']: # start and end hardcoded by parameters\n",
    "        start = parms['master_start']\n",
    "        end = parms['master_end']\n",
    "    else: # end is current date; start is current date minus years_window\n",
    "        end = datetime.now()\n",
    "        start = datetime(end.year - parms['years_window'], end.month, end.day)\n",
    "    # output a test dataset\n",
    "    tester = DataReader('IBM', 'stooq', start, end)\n",
    "    print(tester.shape)\n",
    "    return(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory that is a sibling to the directory containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', fundamentals_directory))\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch load of EOD fundamentals data\n",
    "- https://eodhistoricaldata.com/financial-apis/stock-etfs-fundamental-data-feeds/\n",
    "- base_url = 'https://eodhistoricaldata.com/api/fundamentals/'+symbol\n",
    "\n",
    "Steps:\n",
    "- get fundamentals for an exchange, e.g. base_url = \"https://eodhistoricaldata.com/api/fundamentals/GSPC.INDX\"\n",
    "- parse the resulting JSON to get list of tickers associated with that exchange\n",
    "- get JSON dump from fundamentals API for each ticker in the list\n",
    "- clean up JSON to (a) remove starting and ending quotes, (b) backslashes\n",
    "- save JSON in timestamped JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the JSON fundamentals dump for a given ticker\n",
    "\n",
    "# https://eodhistoricaldata.com/api/fundamentals/AAPL.US?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\n",
    "def get_eod_ticker_fundamentals(symbol='AAPL.US', api_token='OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX'):\n",
    "    session = requests.Session()\n",
    "    base_url = 'https://eodhistoricaldata.com/api/fundamentals/'+symbol\n",
    "    params = {'api_token': api_token}\n",
    "    r = session.get(base_url, params=params)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        df = pd.read_csv(StringIO(r.text), skipfooter=0,index_col=0)\n",
    "        return(True, r)\n",
    "    else:\n",
    "        print(\"status code\",str(r.status_code))\n",
    "        print(\"reason code\",str(r.reason))\n",
    "        return(False,\"null\")\n",
    "        #raise Exception(r.status_code, r.reason, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output JSON file with YMD timestamp\n",
    "\n",
    "def write_json_file(ticker,output_path,json_struct):\n",
    "    str_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    file_name = os.path.join(output_path,ticker+'_'+str_date+'.json')\n",
    "    print(\"file name is: \",file_name)\n",
    "    #json_object = json.dumps(json_struct, indent = 4)\n",
    "    json_object = json_struct\n",
    "    with open(file_name, 'w') as outfile:\n",
    "        json.dump(json_object, outfile)\n",
    "    #with open(file_name, \"w\") as outfile:\n",
    "    #    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_dict_for_exchange(exchange_json):\n",
    "    path = get_path()\n",
    "    file_name = os.path.join(path,exchange_json)\n",
    "    print(\"json file name is: \",file_name)\n",
    "    f = open(file_name,)\n",
    "    exchange_dict = json.load(f)\n",
    "    ticker_dict = exchange_dict['Components']\n",
    "    return(ticker_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\n# ETF only one-time load\\nfor ticker in etf_list:\\n    ticker_name = ticker\\n    ticker_exchange = \\'US\\'\\n    #print(\"ticker_name is: \",ticker_name)\\n    #print(\"ticker_exchange is: \",ticker_exchange)\\n    company = ticker_name+\\'.\\'+ticker_exchange\\n    print(\"company is: \",company)\\n    result_stat, r = get_eod_ticker_fundamentals(company,eod_token)\\n    # clean off the backslashes and starting and ending double quotes\\n    r_text = r.text\\n    json_output = json.loads(r.text)\\n    no_backslash = r_text.replace(\"\\\\\", \"\")\\n    # my_str[:-1]\\n    no_end_quote = no_backslash[:-1]\\n    prepped_json = no_end_quote[1:]\\n    write_json_file(ticker_name,get_path(),json_output)\\n    #i = i+1\\n    #if i >= 3:\\n    #   break\\nprint(\"out of loop\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "# ETF only one-time load\n",
    "for ticker in etf_list:\n",
    "    ticker_name = ticker\n",
    "    ticker_exchange = 'US'\n",
    "    #print(\"ticker_name is: \",ticker_name)\n",
    "    #print(\"ticker_exchange is: \",ticker_exchange)\n",
    "    company = ticker_name+'.'+ticker_exchange\n",
    "    print(\"company is: \",company)\n",
    "    result_stat, r = get_eod_ticker_fundamentals(company,eod_token)\n",
    "    # clean off the backslashes and starting and ending double quotes\n",
    "    r_text = r.text\n",
    "    json_output = json.loads(r.text)\n",
    "    no_backslash = r_text.replace(\"\\\\\", \"\")\n",
    "    # my_str[:-1]\n",
    "    no_end_quote = no_backslash[:-1]\n",
    "    prepped_json = no_end_quote[1:]\n",
    "    write_json_file(ticker_name,get_path(),json_output)\n",
    "    #i = i+1\n",
    "    #if i >= 3:\n",
    "    #   break\n",
    "print(\"out of loop\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\dja_2021-10-28.json\n",
      "company is:  CSX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CSX_2021-10-28.json\n",
      "company is:  SO.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\SO_2021-10-28.json\n",
      "company is:  EIX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\EIX_2021-10-28.json\n",
      "company is:  INTC.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\INTC_2021-10-28.json\n",
      "company is:  MATX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\MATX_2021-10-28.json\n",
      "company is:  MCD.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\MCD_2021-10-28.json\n",
      "company is:  KO.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\KO_2021-10-28.json\n",
      "company is:  GS.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\GS_2021-10-28.json\n",
      "company is:  NKE.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\NKE_2021-10-28.json\n",
      "company is:  PG.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\PG_2021-10-28.json\n",
      "company is:  CHRW.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CHRW_2021-10-28.json\n",
      "company is:  JPM.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\JPM_2021-10-28.json\n",
      "company is:  AAL.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AAL_2021-10-28.json\n",
      "company is:  AEP.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AEP_2021-10-28.json\n",
      "company is:  CNP.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CNP_2021-10-28.json\n",
      "company is:  UNP.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\UNP_2021-10-28.json\n",
      "company is:  KEX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\KEX_2021-10-28.json\n",
      "company is:  R.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\R_2021-10-28.json\n",
      "company is:  LUV.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\LUV_2021-10-28.json\n",
      "company is:  CSCO.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CSCO_2021-10-28.json\n",
      "company is:  LSTR.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\LSTR_2021-10-28.json\n",
      "company is:  JBLU.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\JBLU_2021-10-28.json\n",
      "company is:  CVX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CVX_2021-10-28.json\n",
      "company is:  CAR.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CAR_2021-10-28.json\n",
      "company is:  AAPL.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AAPL_2021-10-28.json\n",
      "company is:  BA.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\BA_2021-10-28.json\n",
      "company is:  DUK.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\DUK_2021-10-28.json\n",
      "company is:  PEG.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\PEG_2021-10-28.json\n",
      "company is:  ALK.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\ALK_2021-10-28.json\n",
      "company is:  FE.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\FE_2021-10-28.json\n",
      "company is:  NSC.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\NSC_2021-10-28.json\n",
      "company is:  TRV.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\TRV_2021-10-28.json\n",
      "company is:  WMT.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\WMT_2021-10-28.json\n",
      "company is:  MMM.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\MMM_2021-10-28.json\n",
      "company is:  AWK.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AWK_2021-10-28.json\n",
      "company is:  XOM.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\XOM_2021-10-28.json\n",
      "company is:  UAL.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\UAL_2021-10-28.json\n",
      "company is:  CAT.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\CAT_2021-10-28.json\n",
      "company is:  JNJ.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\JNJ_2021-10-28.json\n",
      "company is:  EXPD.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\EXPD_2021-10-28.json\n",
      "company is:  KSU.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\KSU_2021-10-28.json\n",
      "company is:  AXP.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AXP_2021-10-28.json\n",
      "company is:  MRK.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\MRK_2021-10-28.json\n",
      "company is:  MSFT.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\MSFT_2021-10-28.json\n",
      "company is:  IBM.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\IBM_2021-10-28.json\n",
      "company is:  AES.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AES_2021-10-28.json\n",
      "company is:  ED.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\ED_2021-10-28.json\n",
      "company is:  DAL.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\DAL_2021-10-28.json\n",
      "company is:  NI.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\NI_2021-10-28.json\n",
      "company is:  DIS.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\DIS_2021-10-28.json\n",
      "company is:  DD.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\DD_2021-10-28.json\n",
      "company is:  V.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\V_2021-10-28.json\n",
      "company is:  GE.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\GE_2021-10-28.json\n",
      "company is:  JBHT.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\JBHT_2021-10-28.json\n",
      "company is:  UPS.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\UPS_2021-10-28.json\n",
      "company is:  D.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\D_2021-10-28.json\n",
      "company is:  VZ.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\VZ_2021-10-28.json\n",
      "company is:  UNH.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\UNH_2021-10-28.json\n",
      "company is:  PCG.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\PCG_2021-10-28.json\n",
      "company is:  FDX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\FDX_2021-10-28.json\n",
      "company is:  PFE.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\PFE_2021-10-28.json\n",
      "company is:  NEE.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\NEE_2021-10-28.json\n",
      "company is:  HD.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\HD_2021-10-28.json\n",
      "company is:  EXC.US\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\EXC_2021-10-28.json\n",
      "company is:  UTX.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\UTX_2021-10-28.json\n",
      "out of loop\n",
      "Wall time: 11min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for exchange in exchange_list:\n",
    "    ticker_dict = get_ticker_dict_for_exchange(exchange)\n",
    "    #print(\"ticker_dict\",ticker_dict)\n",
    "    i = 0\n",
    "    for ticker in ticker_dict:\n",
    "        ticker_name = ticker_dict[ticker]['Code']\n",
    "        ticker_exchange = ticker_dict[ticker]['Exchange']\n",
    "        #print(\"ticker_name is: \",ticker_name)\n",
    "        #print(\"ticker_exchange is: \",ticker_exchange)\n",
    "        company = ticker_name+'.'+ticker_exchange\n",
    "        print(\"company is: \",company)\n",
    "        result_stat, r = get_eod_ticker_fundamentals(company,eod_token)\n",
    "        # clean off the backslashes and starting and ending double quotes\n",
    "        r_text = r.text\n",
    "        json_output = json.loads(r.text)\n",
    "        no_backslash = r_text.replace(\"\\\\\", \"\")\n",
    "        # my_str[:-1]\n",
    "        no_end_quote = no_backslash[:-1]\n",
    "        prepped_json = no_end_quote[1:]\n",
    "        write_json_file(ticker_name,get_path(),json_output)\n",
    "        #i = i+1\n",
    "        #if i >= 3:\n",
    "        #   break\n",
    "    print(\"out of loop\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\ncompany = \\'SPY.US\\'\\ntoken = eod_token\\nstart_date, end_date = set_start_end()\\nresult_stat, r = get_eod_ticker_fundamentals(company,token)\\npath = get_path()\\n# text.split(sep, 1)[0]\\nticker = company.split(\\'.\\',1)[0]\\nprint(\"ticker\")\\nwrite_json_file(ticker,path,r.text)\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single call\n",
    "'''\n",
    "\n",
    "\n",
    "company = 'SPY.US'\n",
    "token = eod_token\n",
    "start_date, end_date = set_start_end()\n",
    "result_stat, r = get_eod_ticker_fundamentals(company,token)\n",
    "path = get_path()\n",
    "# text.split(sep, 1)[0]\n",
    "ticker = company.split('.',1)[0]\n",
    "print(\"ticker\")\n",
    "write_json_file(ticker,path,r.text)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# with open(\"sample.json\", \"w\") as outfile:\\n#    outfile.write(json_object)\\n\\njson_object = json.dumps(r.text, indent = 4)\\nwith open(\"spy.json\", \"w\") as outfile:\\n    outfile.write(json_object)\\n    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# with open(\"sample.json\", \"w\") as outfile:\n",
    "#    outfile.write(json_object)\n",
    "\n",
    "json_object = json.dumps(r.text, indent = 4)\n",
    "with open(\"spy.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsession = requests.Session()\\nbase_url = \"https://eodhistoricaldata.com/api/fundamentals/GSPC.INDX\"\\napi_token = \"605766cf49ac93.89487471\"\\nparams = {\\'api_token\\': api_token}\\nr = session.get(base_url, params=params)\\nif r.status_code == requests.codes.ok:\\n    #df = pd.read_csv(StringIO(r.text), skipfooter=0, parse_dates=[0], index_col=0, engine=\\'python\\')\\n    df = pd.read_csv(StringIO(r.text), skipfooter=0,index_col=0)\\n\\n    \\nelse:\\n    print(\"status code\",str(r.status_code))\\n    print(\"reason code\",str(r.reason))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brute force call \n",
    "# https://eodhistoricaldata.com/api/fundamentals/AAPL.US?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\n",
    "'''\n",
    "session = requests.Session()\n",
    "base_url = \"https://eodhistoricaldata.com/api/fundamentals/GSPC.INDX\"\n",
    "api_token = \"605766cf49ac93.89487471\"\n",
    "params = {'api_token': api_token}\n",
    "r = session.get(base_url, params=params)\n",
    "if r.status_code == requests.codes.ok:\n",
    "    #df = pd.read_csv(StringIO(r.text), skipfooter=0, parse_dates=[0], index_col=0, engine='python')\n",
    "    df = pd.read_csv(StringIO(r.text), skipfooter=0,index_col=0)\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"status code\",str(r.status_code))\n",
    "    print(\"reason code\",str(r.reason))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njson_object = json.dumps(r.text, indent = 4)\\nwith open(\"gspc.json\", \"w\") as outfile:\\n    outfile.write(json_object)\\n    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"sample.json\", \"w\") as outfile:\n",
    "#    outfile.write(json_object)\n",
    "'''\n",
    "json_object = json.dumps(r.text, indent = 4)\n",
    "with open(\"gspc.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
