{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOD: load from fundamentals API\n",
    "\n",
    "- use the fundamentals API to get details about tickers and ETFS\n",
    "- get ticker values from exchange lists and then load fundamentals from that ticker list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import yaml\n",
    "from datetime import date\n",
    "import requests\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "# For reading stock data from yahoo\n",
    "#import pandas_datareader as pdr\n",
    "from pandas_datareader.data import DataReader\n",
    "# import yahoo_fin.stock_info as si\n",
    "\n",
    "# For time stamps\n",
    "from datetime import datetime\n",
    "\n",
    "# for LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input\n",
    "from keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "# access datasets from quandl.com - need to pip install Quandl to use\n",
    "import quandl\n",
    "config_file = 'eod_test_config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is: C:\\personal\\karma_stocks_2021\\stock_investigation\\notebooks\n",
      "path_to_yaml C:\\personal\\karma_stocks_2021\\stock_investigation\\notebooks\\eod_test_config.yml\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "current_path = os.getcwd()\n",
    "print(\"current directory is: \"+current_path)\n",
    "\n",
    "path_to_yaml = os.path.join(current_path, config_file)\n",
    "print(\"path_to_yaml \"+path_to_yaml)\n",
    "try:\n",
    "    with open (path_to_yaml, 'r') as c_file:\n",
    "        config = yaml.safe_load(c_file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config parms\n",
    "parms = {}\n",
    "eod_token = config['general']['eod_token']\n",
    "eod_historical_token = config['general']['eod_historical_token']\n",
    "fundamentals_directory = config['files']['fundamentals_directory']\n",
    "exchange_list = config['exchange_json_list']\n",
    "\n",
    "from_date = config['general']['master_start']\n",
    "to_date = config['general']['master_end']\n",
    "parms['master_date_mode'] = config['general']['master_date_mode']\n",
    "parms['master_start'] = config['general']['master_start']\n",
    "parms['master_end'] = config['general']['master_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataReader: https://riptutorial.com/pandas/topic/1912/pandas-datareader\n",
    "# https://pandas-datareader.readthedocs.io/en/latest/remote_data.html\n",
    "# \n",
    "# Set up End and Start times for data grab\n",
    "# check to see if start and end dates are hard-coded with master dates\n",
    "def set_start_end():\n",
    "    if parms['master_date_mode']: # start and end hardcoded by parameters\n",
    "        start = parms['master_start']\n",
    "        end = parms['master_end']\n",
    "    else: # end is current date; start is current date minus years_window\n",
    "        end = datetime.now()\n",
    "        start = datetime(end.year - parms['years_window'], end.month, end.day)\n",
    "    # output a test dataset\n",
    "    tester = DataReader('IBM', 'stooq', start, end)\n",
    "    print(tester.shape)\n",
    "    return(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory that is a sibling to the directory containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', fundamentals_directory))\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch load of EOD fundamentals data\n",
    "- https://eodhistoricaldata.com/financial-apis/stock-etfs-fundamental-data-feeds/\n",
    "- base_url = 'https://eodhistoricaldata.com/api/fundamentals/'+symbol\n",
    "\n",
    "Steps:\n",
    "- get fundamentals for an exchange, e.g. base_url = \"https://eodhistoricaldata.com/api/fundamentals/GSPC.INDX\"\n",
    "- parse the resulting JSON to get list of tickers associated with that exchange\n",
    "- get JSON dump from fundamentals API for each ticker in the list\n",
    "- clean up JSON to (a) remove starting and ending quotes, (b) backslashes\n",
    "- save JSON in timestamped JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the JSON fundamentals dump for a given ticker\n",
    "\n",
    "# https://eodhistoricaldata.com/api/fundamentals/AAPL.US?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\n",
    "def get_eod_ticker_fundamentals(symbol='AAPL.US', api_token='OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX'):\n",
    "    session = requests.Session()\n",
    "    base_url = 'https://eodhistoricaldata.com/api/fundamentals/'+symbol\n",
    "    params = {'api_token': api_token}\n",
    "    r = session.get(base_url, params=params)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        df = pd.read_csv(StringIO(r.text), skipfooter=0,index_col=0)\n",
    "        return(True, r)\n",
    "    else:\n",
    "        print(\"status code\",str(r.status_code))\n",
    "        print(\"reason code\",str(r.reason))\n",
    "        return(False,\"null\")\n",
    "        #raise Exception(r.status_code, r.reason, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output JSON file with YMD timestamp\n",
    "\n",
    "def write_json_file(ticker,output_path,json_struct):\n",
    "    str_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    file_name = os.path.join(output_path,ticker+'_'+str_date+'.json')\n",
    "    print(\"file name is: \",file_name)\n",
    "    #json_object = json.dumps(json_struct, indent = 4)\n",
    "    json_object = json_struct\n",
    "    with open(file_name, 'w') as outfile:\n",
    "        json.dump(json_object, outfile)\n",
    "    #with open(file_name, \"w\") as outfile:\n",
    "    #    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_dict_for_exchange(exchange_json):\n",
    "    path = get_path()\n",
    "    file_name = os.path.join(path,exchange_json)\n",
    "    print(\"json file name is: \",file_name)\n",
    "    f = open(file_name,)\n",
    "    exchange_dict = json.load(f)\n",
    "    ticker_dict = exchange_dict['Components']\n",
    "    return(ticker_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\gspc_clean.json\n",
      "company is:  AIZ.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\AIZ_2021-10-09.json\n",
      "company is:  MNST.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\MNST_2021-10-09.json\n",
      "company is:  GPS.US\n",
      "file name is:  C:\\personal\\karma_stocks_2021\\stock_investigation\\static_load_fundamentals\\GPS_2021-10-09.json\n",
      "out of loop\n"
     ]
    }
   ],
   "source": [
    "for exchange in exchange_list:\n",
    "    ticker_dict = get_ticker_dict_for_exchange(exchange)\n",
    "    #print(\"ticker_dict\",ticker_dict)\n",
    "    i = 0\n",
    "    for ticker in ticker_dict:\n",
    "        ticker_name = ticker_dict[ticker]['Code']\n",
    "        ticker_exchange = ticker_dict[ticker]['Exchange']\n",
    "        #print(\"ticker_name is: \",ticker_name)\n",
    "        #print(\"ticker_exchange is: \",ticker_exchange)\n",
    "        company = ticker_name+'.'+ticker_exchange\n",
    "        print(\"company is: \",company)\n",
    "        result_stat, r = get_eod_ticker_fundamentals(company,eod_token)\n",
    "        # clean off the backslashes and starting and ending double quotes\n",
    "        r_text = r.text\n",
    "        json_output = json.loads(r.text)\n",
    "        no_backslash = r_text.replace(\"\\\\\", \"\")\n",
    "        # my_str[:-1]\n",
    "        no_end_quote = no_backslash[:-1]\n",
    "        prepped_json = no_end_quote[1:]\n",
    "        write_json_file(ticker_name,get_path(),json_output)\n",
    "        i = i+1\n",
    "        if i >= 3:\n",
    "            break\n",
    "    print(\"out of loop\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\ncompany = \\'SPY.US\\'\\ntoken = eod_token\\nstart_date, end_date = set_start_end()\\nresult_stat, r = get_eod_ticker_fundamentals(company,token)\\npath = get_path()\\n# text.split(sep, 1)[0]\\nticker = company.split(\\'.\\',1)[0]\\nprint(\"ticker\")\\nwrite_json_file(ticker,path,r.text)\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single call\n",
    "'''\n",
    "\n",
    "\n",
    "company = 'SPY.US'\n",
    "token = eod_token\n",
    "start_date, end_date = set_start_end()\n",
    "result_stat, r = get_eod_ticker_fundamentals(company,token)\n",
    "path = get_path()\n",
    "# text.split(sep, 1)[0]\n",
    "ticker = company.split('.',1)[0]\n",
    "print(\"ticker\")\n",
    "write_json_file(ticker,path,r.text)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# with open(\"sample.json\", \"w\") as outfile:\\n#    outfile.write(json_object)\\n\\njson_object = json.dumps(r.text, indent = 4)\\nwith open(\"spy.json\", \"w\") as outfile:\\n    outfile.write(json_object)\\n    '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# with open(\"sample.json\", \"w\") as outfile:\n",
    "#    outfile.write(json_object)\n",
    "\n",
    "json_object = json.dumps(r.text, indent = 4)\n",
    "with open(\"spy.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsession = requests.Session()\\nbase_url = \"https://eodhistoricaldata.com/api/fundamentals/GSPC.INDX\"\\napi_token = \"605766cf49ac93.89487471\"\\nparams = {\\'api_token\\': api_token}\\nr = session.get(base_url, params=params)\\nif r.status_code == requests.codes.ok:\\n    #df = pd.read_csv(StringIO(r.text), skipfooter=0, parse_dates=[0], index_col=0, engine=\\'python\\')\\n    df = pd.read_csv(StringIO(r.text), skipfooter=0,index_col=0)\\n\\n    \\nelse:\\n    print(\"status code\",str(r.status_code))\\n    print(\"reason code\",str(r.reason))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brute force call \n",
    "# https://eodhistoricaldata.com/api/fundamentals/AAPL.US?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\n",
    "'''\n",
    "session = requests.Session()\n",
    "base_url = \"https://eodhistoricaldata.com/api/fundamentals/GSPC.INDX\"\n",
    "api_token = \"605766cf49ac93.89487471\"\n",
    "params = {'api_token': api_token}\n",
    "r = session.get(base_url, params=params)\n",
    "if r.status_code == requests.codes.ok:\n",
    "    #df = pd.read_csv(StringIO(r.text), skipfooter=0, parse_dates=[0], index_col=0, engine='python')\n",
    "    df = pd.read_csv(StringIO(r.text), skipfooter=0,index_col=0)\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"status code\",str(r.status_code))\n",
    "    print(\"reason code\",str(r.reason))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njson_object = json.dumps(r.text, indent = 4)\\nwith open(\"gspc.json\", \"w\") as outfile:\\n    outfile.write(json_object)\\n    '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"sample.json\", \"w\") as outfile:\n",
    "#    outfile.write(json_object)\n",
    "'''\n",
    "json_object = json.dumps(r.text, indent = 4)\n",
    "with open(\"gspc.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
